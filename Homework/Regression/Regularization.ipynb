{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularization\n",
    "\n",
    "Note that solutions to these problems require the material covered in the `Basic Pipelines` notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the packages we'll use\n",
    "## For data handling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import meshgrid\n",
    "\n",
    "## For plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "## This sets the plot style\n",
    "## to have a grid on a white background\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theoretical Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Deriving the Ridge Regression Estimator\n",
    "\n",
    "Recall that finding the ridge regression coefficients involves minimizing the following:\n",
    "$$\n",
    "||y-X\\beta||_2^2 + \\alpha ||\\beta||_2^2.\n",
    "$$\n",
    "But, this can be rewritten like so:\n",
    "$$\n",
    "(y-X\\beta)^T(y-X\\beta) + \\alpha \\beta^T \\beta.\n",
    "$$\n",
    "\n",
    "Derive the estimate, $\\hat{\\beta}$ that minimizes this expression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applied"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Building your own Ridge Regression estimator.\n",
    "\n",
    "Using your answer to the Question 1. from the Theoretical section Write code using `numpy` to find the ridge regression coefficients for the following data. Remembering to include the normalizing step using `StandardScaler`. Fit the data with a high degree polynomial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The Data\n",
    "x_train = 3*(np.pi/2)*np.random.random(500) - 2*np.pi\n",
    "y_train = np.sin(x_train) + .3*np.random.randn(500)\n",
    "\n",
    "x_test = 3*(np.pi/2)*np.random.random(500) - 2*np.pi\n",
    "y_test = np.sin(x_test) + .3*np.random.randn(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. The Elastic Net Algorithm\n",
    "\n",
    "Elastic Net is a regularization regression algorithm that strives to set a middle ground between ridge regression and lasso. Here we set out to minimize:\n",
    "$$\n",
    "MSE + r\\alpha ||\\beta||_1 + \\frac{1-r}{2}\\alpha ||\\beta||_2^2, \\text{ for } r \\in [0,1].\n",
    "$$\n",
    "\n",
    "$r$ is another hyperparameter, when $r=1$ we recover ridge regression. If $r=0$ we recover lasso.\n",
    "\n",
    "Find the best elastic net model that includes all of the features from this `auto` data set to predict `mpg`. Learn about that data set here <a href=\"https://vincentarelbundock.github.io/Rdatasets/doc/ISLR/Auto.html\">https://vincentarelbundock.github.io/Rdatasets/doc/ISLR/Auto.html</a>. Use cv find the best values for $r$ and $\\alpha$. You can read the `ElasticNet` documentation here, <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html\">https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html</a>.\n",
    "\n",
    "I'll prepare the data for you to save time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto = pd.read_csv(\"auto.csv\")\n",
    "\n",
    "auto.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_train = auto.copy().sample(frac=.75, random_state = 440)\n",
    "auto_test = auto.copy().drop(auto_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_matrix(auto, figsize=(14,14), alpha=1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`mpg`-is the target variable and continuous\n",
    "\n",
    "`cylinders` is a feature, and categorical so we need to make dummy variables\n",
    "\n",
    "`displacement` is a continuous feature\n",
    "\n",
    "`weight` is a continuous feature\n",
    "\n",
    "`acceleration` is a continuous feature\n",
    "\n",
    "`year`, is not necessarily a continuous feature, but let's treat it that way for the purposes of this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## preprocess data\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# get one hot encoded variables for cylinders\n",
    "auto_train[['three','four','five','six']] = pd.get_dummies(auto_train['cylinders'])[[3,4,5,6]]\n",
    "\n",
    "X = np.empty((len(auto_train),8))\n",
    "\n",
    "X[:,:4] = np.array(auto_train[['three','four','five','six']])\n",
    "\n",
    "X[:,4:] = scaler.fit_transform(np.array(auto_train[['displacement','weight','acceleration','year']]))\n",
    "\n",
    "y = np.array(auto_train['mpg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here\n",
    "\n",
    "## Import Cross Validation\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here\n",
    "\n",
    "## Run Cross Validation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here\n",
    "\n",
    "## find the optimal alpha and r\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Feature selection for Advertising\n",
    "\n",
    "Return to the best model we settled on for the Advertising data set in notebook 4. Using Ridge or Lasso Regression for feature selection in this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ads = pd.read_csv(\"Advertising.csv\")\n",
    "\n",
    "ads_train = ads.copy().sample(frac=.75, random_state = 440)\n",
    "ads_test = ads.copy().drop(ads_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make the features we were interested in from class\n",
    "ads_train['sqrt_TV'] = np.sqrt(ads_train['TV'])\n",
    "ads_train['sqrtTV_radio'] = ads_train['sqrt_TV'] * ads_train['radio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook was written for the Erd&#337;s Institute C&#337;de Data Science Boot Camp by Matthew Osborne, Ph. D., 2021.\n",
    "\n",
    "Redistribution of the material contained in this repository is conditional on acknowledgement of Matthew Tyler Osborne, Ph.D.'s original authorship and sponsorship of the Erd≈ës Institute as subject to the license (see License.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
